# Face detection using CascadeClassifier

OpenCV is a set of tool where we can find efficient implementation facing common challenges inside computer vision area like face detection in images and videos.

Let's check how we can implement an easy face detector using a well-know CascadeClassifier in OpenCV. This classifier is based on Viola & Jones work which it is used a kind of vector feature called "Haar features" and a boosting algorithm called Adaboost which is a classifier composed by weak classifiers.

As we know now how load an image we can use it in a face detection classifier to try to detect some faces in the photo. To do that we need to import cv2 library and create a CascadeClassifier function from cv2 library.

```python
%pylab inline
 
import dataiku
from dataiku import pandasutils as pdu
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import cv2
 
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_Default.xml")
```

As you can see CascadeClassifier function receive a parameter which is a file system path where a XML file  is located. We will talk about this XML in short but something you need to know is that this XML reside in the Dataiku server where we have our workspace. In this case we are in Dataiku Design Node where we can design, train and test our first model versions.

Now, turn back again in to the XML file. CascadeClassifier need a knowledge built training a Adaboost algorithm. However, there are previous pre-trained models available based on Haar Features. You can see more pre-trained models in this github project here. The pre-trained model are in XML format contained the output of the hyper-parameters and other metadata information that CascadeClassifier needs to create a classifier object. 

<img src="images/haar_features.png?raw=true" width="600" height="350" alt="Dataset section"/>

In this example we are interested in create a Face Classifier so we need the haarcascade_frontalface_Default.xml containing the information to detect frontal faces. You can download this file from github project we told previously but OpenCV library installation comes with a version of this file too. As you can see in previous code block we are referencing haarcascade_frontalface_Default.xml but concatenate it with cv2.data.haarcascades. This constant contains the path where this file is locate in the file system you are working the Dataiku project (Design node in this case).

To this project we have created a Managed Folder called "skmp_folder" where we will upload the image we will use. To load the image using OpenCV we need to download the image as a bytes stream and then formate the stream as a numpy array using unsigned integer data type (line 3). Then, we decode the numpy array according with the OpenCV structure. OpenCV was built to recognize the colors in each image in BGR (Blue Green Red) but usually we use RGB color model so we need additionl step to parse BGR model to RGB model (line 5).

```python
ds2 = dataiku.Folder("skmp_folder")
with ds2.get_download_stream(path='datateam.jpg') as stream:
        nparr = np.fromstring(stream.read(), np.uint8)
        img2 = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)
```

You can show the loaded image in the notebook with:

```python
plt.imshow(img2)
plt.show()
```


<img src="images/dataiku-opencv-face-1.png?raw=true" width="600" height="350" alt="Dataset section"/>

Finally, we can use face_cascade object and use the detectMultiScale function to perform the face detection.

```python
gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
faces = face_cascade.detectMultiScale(gray,1.2,4)
# Draw rectangle around the faces
for (x, y, w, h) in faces:
    cv2.rectangle(img2, (x, y), (x+w, y+h), (0, 255, 0), 20)
# Display the output
plt.imshow(img2)
plt.show()
```

Before, an important step can be performed previous the face detection. The Viola & Jones approach does not use any color feature in the image so it is not necessary to use a RGB color model (considering three matrix for each color) instead we can only use a gray color model (only one matriz) during the detection process. This will reduce the detection process time because the algorithm required less data to compute. To do that we create a gray image version based on the original one (line 1).


<img src="images/dataiku-opencv-face-2.png?raw=true" width="600" height="350" alt="Dataset section"/>

The output of the detectMultiScale function is an object containing all the faces detect in the image. Main information this object has is the coordinate (x,y) where the start the crop of the detection and the width and height of the same. We use this information to draw a green rectangle in the original image.
